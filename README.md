# ğŸ›ï¸ Myntra Review Scraper & Dashboard

A powerful **Python-based** project that scrapes product reviews from Myntra, stores them in **MongoDB** (or local backups), and visualizes insights using a **Streamlit dashboard**.

Get **real-time** reviews, ratings, and pricing info for Myntra products â€” scraped, structured, and visualized in style.

---

## ğŸ“¦ Features
- âœ… Scrapes **multiple product listings** and their reviews from Myntra  
- âœ… Extracts **product details**: name, price, rating, reviews, reviewer name & date  
- âœ… Handles **infinite scrolling** to capture all reviews  
- âœ… Stores reviews in **MongoDB** or saves locally as **CSV** if offline  
- âœ… Visualizes key insights using **Streamlit + Plotly**  
- âœ… Robust fallback and **error-handling mechanisms**  

---

## ğŸ› ï¸ Tech Stack

| Component     | Technology                           |
|--------------|---------------------------------------|
| **Backend**  | Python, Selenium, BeautifulSoup       |
| **Data**     | Pandas, MongoDB                        |
| **Dashboard**| Streamlit, Plotly                      |
| **Cloud**    | MongoDB Atlas                          |

---

## ğŸ“‚ Project Structure
â”œâ”€â”€ scrape.py # Core web scraper using Selenium + BS4

â”œâ”€â”€ generate_data_report.py # Streamlit dashboard generator

â”œâ”€â”€ init.py # MongoDB I/O operations (MongoIO class)

â”œâ”€â”€ data.csv # Example scraped data

â”œâ”€â”€ data_backup/ # Local CSV backups if MongoDB fails

â”œâ”€â”€ requirements.txt # All dependencies

â””â”€â”€ README.md # Project documentation

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/myntra-review-scraper.git
cd myntra-review-scraper

2ï¸âƒ£ Set Up Environment

Make sure you have Python 3.8+ installed.

Install dependencies:
pip install -r requirements.txt
3ï¸âƒ£ MongoDB Setup
Create a MongoDB Atlas cluster

Whitelist your IP & get the connection string

Replace it inside __init__.py â†’ mongo_db_url

ğŸ’¡ No MongoDB? No problem!
The script automatically saves data locally in data_backup/ if MongoDB is unreachable.

ğŸš€ Usage
Option 1: Run the Scraper Script
bash
Copy
Edit
python scrape.py
Or use programmatically:

python
Copy
Edit
from scrape import ScrapeReviews

scraper = ScrapeReviews(product_name="Nike Shoes", no_of_products=3)
df = scraper.get_review_data()
print(df.head())
Option 2: Visualize with Streamlit
bash
Copy
Edit
streamlit run generate_data_report.py
ğŸ“Š Dashboard Insights
The Streamlit dashboard includes:

ğŸ“ˆ Average price & rating charts

âœ… Best reviews

âŒ Worst reviews

ğŸ“† Review date trends

ğŸ”¢ Rating distribution

All interactive and beautiful â€” thanks to Plotly and Streamlit.

ğŸ§  Offline Mode
If your internet drops or MongoDB is unreachable:

Data is stored in /data_backup/

You can still generate reports from saved CSVs

ğŸ§ª Sample Data Format (data.csv)
Product Name	Over_All_Rating	Price	Date	Rating	Name	Comment

ğŸ“Œ To-Do / Future Ideas
 Add CLI tool for interactive product selection

 Deploy dashboard on Streamlit Cloud

 Integrate sentiment analysis on comments

 Schedule scraper with cron job

 Add GUI using Tkinter or a web frontend

ğŸ“„ License
MIT License â€” Do what you want, but donâ€™t be evil ğŸ˜ˆ

ğŸ‘¨â€ğŸ’» Author
Chandan â€“ LinkedIn
